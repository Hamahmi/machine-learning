{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Hamahmi/machine-learning/blob/master/MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ybenv8OlvPO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Neural Network to classify MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "yE0oMVVzoEyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "\n",
        "In this tutorial we will use [Deep Neural Networks](https://en.wikipedia.org/wiki/Deep_learning) to classify hand digit characters in the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "We will use a higher level library called [keras](https://keras.io/backend/) with tensorflow as the backend."
      ]
    },
    {
      "metadata": {
        "id": "op7g7DW7vez0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing All Libraries\n",
        "\n",
        "I prefere that all importings to be first but ofcourse you can import anywhere (This is Python, not as restrected as java :D )"
      ]
    },
    {
      "metadata": {
        "id": "c8eBW1mhvKlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "30979cda-b64a-4c39-d74f-a6149ce20886"
      },
      "cell_type": "code",
      "source": [
        "# Import libraries necessary for this project\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets       import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models         import Sequential\n",
        "from keras.layers         import Dense\n",
        "from keras.layers         import Dropout\n",
        "from matplotlib.pyplot    import imshow\n",
        "from PIL                  import Image\n",
        "from random               import randint\n",
        "\n",
        "\n",
        "print(\"\\nImporting ✓\\n\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Importing ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PArinEEJwK6r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the Data\n",
        "We will load the data into x_train, y_train and x_test, y_test, in the next section we will get information about the data."
      ]
    },
    {
      "metadata": {
        "id": "Gz3fLb29vcWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "07889127-f948-4692-89d9-df8327cd7338"
      },
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"\\nLoading ✓\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IyP0590q2cqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring the data\n",
        "This step is a very important step, sice we need to know the characteristics of the data to choose later the algorithm with which we can classify the data and which accuracy metric you are going to use. We will know the shape the data is saved with and the classes we have.\n",
        "\n",
        "In the 2nd part of the code we will get a point from the training set and print an image of it along with the class to get an idea of the data points."
      ]
    },
    {
      "metadata": {
        "id": "jSza3Xltytgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "3a5055cf-865a-4d36-c6e4-418f444c3f27"
      },
      "cell_type": "code",
      "source": [
        "print(\"There are\", x_train.shape[0] , \"training examples.\")\n",
        "print(\"And\",  x_test.shape[0], \"testing examples.\")\n",
        "print(\"The images are with dimensions :\", x_train.shape[1] ,\"x\", x_train.shape[2])\n",
        "print(\"\\nThe classes we have are :\",np.unique(y_train))\n",
        "\n",
        "%matplotlib inline\n",
        "# everytime you run you'll get another data point \n",
        "random = randint(0, 60000)\n",
        "print (\"\\nThe class you got is\",y_train[random])\n",
        "imshow(x_train[random])\n",
        "print(\"\\nExploring ✓\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 60000 training examples.\n",
            "And 10000 testing examples.\n",
            "The images are with dimensions : 28 x 28\n",
            "\n",
            "The classes we have are : [0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "The class you got is 2\n",
            "\n",
            "Exploring ✓\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHSpAAZdKoBBlwpg0KUCGHSpAP8P0bfoXm4h9BMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd4b5afbb00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvHGg--UqVFA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One can see that the dataset consists of 60,000 training example each is a 2D array as an image of dimention 28 * 28. One can also see that we have 10 classes which represent the digits from 0 to 9 crossponding to the data."
      ]
    },
    {
      "metadata": {
        "id": "Yl431du5AM24",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshaping the Data to fit the Model\n",
        "\n",
        "Since we are deciding to make a sequential model the data needs to be reshaped to fit as following :\n",
        "-  Reshaping the input data from 2D array with dimension of 28x28 to a 1D vector with a size of 784 in order to pass it to the Deep Neural Network.\n",
        "- Normalizing the input data that ranges from 0 to 255 to range from 0 to 1 by deviding it by 255.\n",
        "- Using to_categorial to split the output into 10 distinct  class labels so that we can use the [Softmax function](https://en.wikipedia.org/wiki/Softmax_function) as out multicalss classifier in the next section."
      ]
    },
    {
      "metadata": {
        "id": "oCZRcFIz71Cg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7b227e68-963e-45d9-b57e-733e7ce1a0c7"
      },
      "cell_type": "code",
      "source": [
        "# Rehaping the data from 2D array with size 28x28 to 1D array (vector) with size 784\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test  =  x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "#  Normalizing the data to be in range from 0 to 1 instead of 0 to 255 \n",
        "x_train = x_train / 255\n",
        "x_test  = x_test  / 255\n",
        "print (x_train.shape)\n",
        "print ( x_test.shape)\n",
        "\n",
        "# Splitting the output to 10 distinct calsses\n",
        "y_train = to_categorical(y_train,num_classes = 10)\n",
        "y_test  = to_categorical( y_test,num_classes = 10)\n",
        "print(y_train.shape)\n",
        "print( y_test.shape)\n",
        "\n",
        "print(\"\\nReshaping ✓\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n",
            "\n",
            "Reshaping ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7o_KVfF2WYZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Selectin the Model\n",
        "\n",
        "The model is a [sequential model](https://keras.io/models/sequential/) with 1 hidden layar (_ofcourse you can use more than 1 hidden layar, in fact just uncomment the line after TODO and rerun all the following codes again and see the difference yourself_) with 1024 neurons, ReLU and an output layar with 10 neurons, Softmax as out multiclass classifier as explained above."
      ]
    },
    {
      "metadata": {
        "id": "_SXNb4MJ1_ZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "848bbb61-166f-479a-86a4-22f9805f9541"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(units=1024, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# TODO \n",
        "# Add another hidden layar(s) as below and rerun all the following codes to observe\n",
        "# model.add(Dense(units=1024, activation='relu' ))\n",
        "# model.add(Dense(units=512 , activation='relu' ))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nCompiling ✓\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Compiling ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9h2Zy3zb5QUg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "In this section we will train the Network on the data we have with 30 epochs and 60% of the data as training set, 20% as validation and the remaining 20% as a test set that we will evaluate the model on in the next section."
      ]
    },
    {
      "metadata": {
        "id": "fpFTAqC94FGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "6f8c7617-2d20-4f8b-88e4-d712b79ac2f5"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=30, batch_size=200, validation_split=0.2, verbose=2)\n",
        "print(\"\\nTraining ✓\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/30\n",
            " - 6s - loss: 0.2964 - acc: 0.9168 - val_loss: 0.1449 - val_acc: 0.9603\n",
            "Epoch 2/30\n",
            " - 6s - loss: 0.1195 - acc: 0.9653 - val_loss: 0.1121 - val_acc: 0.9658\n",
            "Epoch 3/30\n",
            " - 6s - loss: 0.0761 - acc: 0.9780 - val_loss: 0.0958 - val_acc: 0.9716\n",
            "Epoch 4/30\n",
            " - 6s - loss: 0.0532 - acc: 0.9850 - val_loss: 0.0847 - val_acc: 0.9753\n",
            "Epoch 5/30\n",
            " - 6s - loss: 0.0377 - acc: 0.9893 - val_loss: 0.0762 - val_acc: 0.9780\n",
            "Epoch 6/30\n",
            " - 5s - loss: 0.0277 - acc: 0.9928 - val_loss: 0.0817 - val_acc: 0.9761\n",
            "Epoch 7/30\n",
            " - 6s - loss: 0.0201 - acc: 0.9949 - val_loss: 0.0798 - val_acc: 0.9772\n",
            "Epoch 8/30\n",
            " - 5s - loss: 0.0141 - acc: 0.9970 - val_loss: 0.0725 - val_acc: 0.9799\n",
            "Epoch 9/30\n",
            " - 5s - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0718 - val_acc: 0.9796\n",
            "Epoch 10/30\n",
            " - 5s - loss: 0.0072 - acc: 0.9990 - val_loss: 0.0709 - val_acc: 0.9808\n",
            "Epoch 11/30\n",
            " - 6s - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0834 - val_acc: 0.9774\n",
            "Epoch 12/30\n",
            " - 6s - loss: 0.0038 - acc: 0.9998 - val_loss: 0.0736 - val_acc: 0.9798\n",
            "Epoch 13/30\n",
            " - 6s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0762 - val_acc: 0.9800\n",
            "Epoch 14/30\n",
            " - 6s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9808\n",
            "Epoch 15/30\n",
            " - 6s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9813\n",
            "Epoch 16/30\n",
            " - 6s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9814\n",
            "Epoch 17/30\n",
            " - 6s - loss: 8.4248e-04 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9814\n",
            "Epoch 18/30\n",
            " - 6s - loss: 6.8383e-04 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9810\n",
            "Epoch 19/30\n",
            " - 6s - loss: 6.3267e-04 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9812\n",
            "Epoch 20/30\n",
            " - 6s - loss: 4.9886e-04 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 0.9816\n",
            "Epoch 21/30\n",
            " - 6s - loss: 4.5127e-04 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 0.9818\n",
            "Epoch 22/30\n",
            " - 6s - loss: 3.7072e-04 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9812\n",
            "Epoch 23/30\n",
            " - 6s - loss: 3.0250e-04 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9813\n",
            "Epoch 24/30\n",
            " - 6s - loss: 2.6228e-04 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9814\n",
            "Epoch 25/30\n",
            " - 6s - loss: 2.3005e-04 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9819\n",
            "Epoch 26/30\n",
            " - 6s - loss: 2.0521e-04 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9815\n",
            "Epoch 27/30\n",
            " - 6s - loss: 1.7191e-04 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9819\n",
            "Epoch 28/30\n",
            " - 6s - loss: 1.5100e-04 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9823\n",
            "Epoch 29/30\n",
            " - 6s - loss: 1.2810e-04 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9815\n",
            "Epoch 30/30\n",
            " - 6s - loss: 1.1071e-04 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9816\n",
            "\n",
            "Training ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LIiGK4zfBTPj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Results to evaluate the model\n",
        "\n",
        "Now we will evaluate the model we have on the test set to see the accuracy we get."
      ]
    },
    {
      "metadata": {
        "id": "oSiyA5lB55qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9d0c562-2eb6-4f0b-dd94-4b00de975ef5"
      },
      "cell_type": "code",
      "source": [
        "(error, accuracy) = model.evaluate(x_test, y_test)\n",
        "print( \"test error = \", error)\n",
        "print(\"accuracy = \", accuracy*100, \"%\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 82us/step\n",
            "test error =  0.07381055212803463\n",
            "accuracy =  98.29 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXS_MxM3BlyM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*End of the Project :)*"
      ]
    },
    {
      "metadata": {
        "id": "fP94GYtBFO5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Drive](https://colab.research.google.com/drive/1CaoOf0YDyWBvkRGSHfUxM4bHuO2t4o5x#scrollTo=Ybenv8OlvPO9)"
      ]
    },
    {
      "metadata": {
        "id": "Zi7VIvpnBo6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4957311-7cc9-48d3-d8f2-45ebcae9df7b"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nPROJECT ✓\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "PROJECT ✓\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}